
@article{guyon_gene_2002,
	title = {Gene {Selection} for {Cancer} {Classification} using {Support} {Vector} {Machines}},
	volume = {46},
	issn = {1573-0565},
	doi = {10.1023/A:1012487302797},
	abstract = {DNA micro-arrays now permit scientists to screen thousands of genes simultaneously and determine whether those genes are active, hyperactive or silent in normal or cancerous tissue. Because these new micro-array devices generate bewildering amounts of raw data, new analytical methods must be developed to sort out whether cancer tissues have distinctive signatures of gene expression over normal tissues or other types of cancer tissues.},
	language = {en},
	number = {1},
	journal = {Machine Learning},
	author = {Guyon, Isabelle and Weston, Jason and Barnhill, Stephen and Vapnik, Vladimir},
	month = jan,
	year = {2002},
	pages = {389--422},
	file = {Springer Full Text PDF:C\:\\Users\\Maou\\Zotero\\storage\\WMQUJMBF\\Guyon et al. - 2002 - Gene Selection for Cancer Classification using Sup.pdf:application/pdf},
}

@article{saeys_review_2007,
	title = {A review of feature selection techniques in bioinformatics},
	volume = {23},
	issn = {1367-4803},
	doi = {10.1093/bioinformatics/btm344},
	abstract = {Feature selection techniques have become an apparent need in many bioinformatics applications. In addition to the large pool of techniques that have already been developed in the machine learning and data mining fields, specific applications in bioinformatics have led to a wealth of newly proposed techniques.In this article, we make the interested reader aware of the possibilities of feature selection, providing a basic taxonomy of feature selection techniques, and discussing their use, variety and potential in a number of both common as well as upcoming bioinformatics applications.Contact:yvan.saeys@psb.ugent.beSupplementary information:http://bioinformatics.psb.ugent.be/supplementary\_data/yvsae/fsreview},
	number = {19},
	journal = {Bioinformatics},
	author = {Saeys, Yvan and Inza, Iñaki and Larrañaga, Pedro},
	month = oct,
	year = {2007},
	pages = {2507--2517},
	file = {Full Text PDF:C\:\\Users\\Maou\\Zotero\\storage\\6LMUICI8\\Saeys et al. - 2007 - A review of feature selection techniques in bioinf.pdf:application/pdf;Snapshot:C\:\\Users\\Maou\\Zotero\\storage\\9QEVELTZ\\185254.html:text/html},
}

@article{li_feature_2017,
	title = {Feature {Selection}: {A} {Data} {Perspective}},
	volume = {50},
	issn = {0360-0300},
	shorttitle = {Feature {Selection}},
	url = {https://doi.org/10.1145/3136625},
	doi = {10.1145/3136625},
	abstract = {Feature selection, as a data preprocessing strategy, has been proven to be effective and efficient in preparing data (especially high-dimensional data) for various data-mining and machine-learning problems. The objectives of feature selection include building simpler and more comprehensible models, improving data-mining performance, and preparing clean, understandable data. The recent proliferation of big data has presented some substantial challenges and opportunities to feature selection. In this survey, we provide a comprehensive and structured overview of recent advances in feature selection research. Motivated by current challenges and opportunities in the era of big data, we revisit feature selection research from a data perspective and review representative feature selection algorithms for conventional data, structured data, heterogeneous data and streaming data. Methodologically, to emphasize the differences and similarities of most existing feature selection algorithms for conventional data, we categorize them into four main groups: similarity-based, information-theoretical-based, sparse-learning-based, and statistical-based methods. To facilitate and promote the research in this community, we also present an open source feature selection repository that consists of most of the popular feature selection algorithms (http://featureselection.asu.edu/). Also, we use it as an example to show how to evaluate feature selection algorithms. At the end of the survey, we present a discussion about some open problems and challenges that require more attention in future research.},
	number = {6},
	urldate = {2021-03-01},
	journal = {ACM Comput. Surv.},
	author = {Li, Jundong and Cheng, Kewei and Wang, Suhang and Morstatter, Fred and Trevino, Robert P. and Tang, Jiliang and Liu, Huan},
	month = dec,
	year = {2017},
	keywords = {Feature selection},
	pages = {94:1--94:45},
	file = {Full Text PDF:C\:\\Users\\Maou\\Zotero\\storage\\9N99BN2E\\Li et al. - 2017 - Feature Selection A Data Perspective.pdf:application/pdf},
}

@article{guyon_introduction_2003,
	title = {An {Introduction} to {Variable} and {Feature} {Selection}},
	volume = {3},
	issn = {1533-7928},
	abstract = {Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. These areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. The objective of variable selection is three-fold: improving the prediction performance of the predictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data. The contributions of this special issue cover a wide range of aspects of such problems: providing a better deﬁnition of the objective function, feature construction, feature ranking, multivariate feature selection, efﬁcient search methods, and feature validity assessment methods.},
	number = {Mar},
	journal = {Journal of Machine Learning Research},
	author = {Guyon, Isabelle and Elisseeff, André},
	year = {2003},
	pages = {1157--1182},
	file = {Full Text PDF:C\:\\Users\\Maou\\Zotero\\storage\\JCIGW6GC\\Guyon and Elisseeff - 2003 - An Introduction to Variable and Feature Selection.pdf:application/pdf},
}
